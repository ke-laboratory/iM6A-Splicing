{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kelab/m6AAIpy2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from pkg_resources import resource_filename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import keras.backend as kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(seq):\n",
    "\n",
    "    map = np.asarray([[0, 0, 0, 0],\n",
    "                      [1, 0, 0, 0],\n",
    "                      [0, 1, 0, 0],\n",
    "                      [0, 0, 1, 0],\n",
    "                      [0, 0, 0, 1]])\n",
    "\n",
    "    seq = seq.upper().replace('A', '\\x01').replace('C', '\\x02')\n",
    "    seq = seq.replace('G', '\\x03').replace('T', '\\x04').replace('N', '\\x00')\n",
    "\n",
    "    return map[np.fromstring(seq, np.int8) % 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy_2d(y_true, y_pred):\n",
    "    # Standard categorical cross entropy for sequence outputs\n",
    "\n",
    "    return - kb.mean(y_true[:, :, 0]*kb.log(y_pred[:, :, 0]+1e-10)\n",
    "                   + y_true[:, :, 1]*kb.log(y_pred[:, :, 1]+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ('/home/kelab/Desktop/iM6A/mouseRAC10000_c{}.h5'.format(x) for x in range(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kelab/m6AAIpy2/keras/backend/tensorflow_backend.py:1154: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/kelab/m6AAIpy2/keras/backend/tensorflow_backend.py:1190: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/kelab/m6AAIpy2/keras/backend/tensorflow_backend.py:1297: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "models = [load_model(y, custom_objects={'categorical_crossentropy_2d': categorical_crossentropy_2d}) for y in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7f4d36fea650>,\n",
       " <keras.engine.training.Model at 0x7f4d31840810>,\n",
       " <keras.engine.training.Model at 0x7f4baa1d0d10>,\n",
       " <keras.engine.training.Model at 0x7f4a4d19ddd0>,\n",
       " <keras.engine.training.Model at 0x7f4a489c7e90>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta = pd.read_csv(\"Temp/mm10_Fasta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select positive strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Pos = Fasta[Fasta[\"strand\"]==\"+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Pos = Fasta_Pos.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequence = Fasta_Pos[\"Sequence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Fasta_Pos)):\n",
    "    \n",
    "    # Define exon location   \n",
    "    Exon = []\n",
    "    a = Fasta_Pos.loc[i, \"exonStarts\"].split(\",\")[0:-1]\n",
    "    b = Fasta_Pos.loc[i, \"exonEnds\"].split(\",\")[0:-1]\n",
    "    A = [int(u) for u in a]\n",
    "    B = [int(v) for v in b]\n",
    "    Exon = A + B\n",
    "    Exon = sorted(Exon)\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    # Define length of exon and intron\n",
    "    Length = []\n",
    "    for j in range(1,len(Exon),1):\n",
    "        length = Exon[j] - Exon[-1 + j]\n",
    "        Length.append(length)\n",
    "    \n",
    "    CumSum = []\n",
    "    Sum = 0\n",
    "    for k in Length:\n",
    "        Sum = Sum + k\n",
    "        CumSum.append(Sum)    \n",
    "    \n",
    "    \n",
    "    # Define sequence of exon and intron\n",
    "    input_sequence = Sequence[i]\n",
    "    \n",
    "    First = [input_sequence[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        seq = input_sequence[(CumSum[m-1]):(CumSum[m])]\n",
    "        First.append(seq)\n",
    "    \n",
    "    # Define sequence of exon\n",
    "    sequence = \"\"\n",
    "    Sum = 0\n",
    "    CumSum = []\n",
    "    for n in range(0,len(First),2):\n",
    "        seq = First[n]\n",
    "        Sum = Sum + len(seq)\n",
    "        sequence = sequence + seq\n",
    "        CumSum.append(Sum)  \n",
    "    \n",
    "    # Prediction\n",
    "    x = one_hot_encode('N'*(context//2) + sequence + 'N'*(context//2))[None, :]\n",
    "    y = np.mean([models[m].predict(x) for m in range(5)], axis=0)\n",
    "    m6AAI_prob = y[0, :, 1]\n",
    "    m6AAI_prob = m6AAI_prob.tolist()\n",
    "\n",
    "    # Define probability in cDNA\n",
    "    First_prob = [m6AAI_prob[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        prob = m6AAI_prob[(CumSum[m-1]):(CumSum[m])]\n",
    "        First_prob.append(prob)\n",
    "        \n",
    "    # Define intron length\n",
    "    IntronLength = []\n",
    "    for n in range(1,len(Length),2):\n",
    "        intron = Length[n]\n",
    "        IntronLength.append(intron)\n",
    "    IntronLength.append(0)\n",
    "    \n",
    "    Probability = []\n",
    "    for o in range(0,len(First_prob),1):\n",
    "        List = First_prob[o]\n",
    "        Intron = [0]*IntronLength[o]\n",
    "        Probability.append(List+Intron)\n",
    "        \n",
    "    iM6A_prob = []\n",
    "    for t in Probability:\n",
    "        iM6A_prob = iM6A_prob + t\n",
    "    Probability = iM6A_prob        \n",
    "\n",
    "    Probability = pd.DataFrame({'Probability':Probability})\n",
    "    df = pd.DataFrame(np.random.randn((Fasta_Pos.loc[i,\"Length\"]), 3))\n",
    "    df.columns = [\"name\", \"chrom\", \"strand\"]\n",
    "    df[\"name\"] = Fasta_Pos.loc[i,\"name\"]\n",
    "    df[\"chrom\"] = Fasta_Pos.loc[i,\"chrom\"]\n",
    "    df[\"strand\"] = Fasta_Pos.loc[i,\"strand\"]\n",
    "    \n",
    "    list = range(Fasta_Pos.loc[i,\"txStart\"], Fasta_Pos.loc[i,\"txEnd\"])\n",
    "    Start = pd.DataFrame(list, columns=[\"Start\"])\n",
    "    df = pd.concat([df, Start], axis=1)\n",
    "    df[\"End\"] = df[\"Start\"]\n",
    "    df = pd.concat([df, Probability], axis=1)\n",
    "    \n",
    "    df.columns = [\"name\", \"chrom\", \"strand\", \"Start\", \"End\", \"Probabilty\"]\n",
    "    df = df[df[\"Probabilty\"] >= 0.001]\n",
    "    df.to_csv(\"./OutputsIL/{}.bed\".format(Fasta_Pos.loc[i,\"name\"]), sep=\"\\t\", index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select negative strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Neg = Fasta[Fasta[\"strand\"]==\"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Neg = Fasta_Neg.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequence = Fasta_Neg[\"Sequence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Fasta_Neg)):\n",
    "    \n",
    "    # Define exon location\n",
    "    Exon = []\n",
    "    a = Fasta_Neg.loc[i, \"exonStarts\"].split(\",\")[0:-1]\n",
    "    b = Fasta_Neg.loc[i, \"exonEnds\"].split(\",\")[0:-1]\n",
    "    A = [int(u) for u in a]\n",
    "    B = [int(v) for v in b]\n",
    "    Exon = A + B\n",
    "    Exon = sorted(Exon)\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    # Define length of exon and intron\n",
    "    Length = []\n",
    "    for j in range(1,len(Exon),1):\n",
    "        length = Exon[j] - Exon[-1 + j]\n",
    "        Length.append(length)\n",
    "    Length = Length[::-1]\n",
    "    \n",
    "    CumSum = []\n",
    "    Sum = 0\n",
    "    for k in Length:\n",
    "        Sum = Sum + k\n",
    "        CumSum.append(Sum)\n",
    "   \n",
    "    # Define sequence of exon and intron\n",
    "    input_sequence = Sequence[i]\n",
    "    \n",
    "    First = [input_sequence[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        seq = input_sequence[(CumSum[m-1]):(CumSum[m])]\n",
    "        First.append(seq)\n",
    "        \n",
    "    # Define sequence of exon\n",
    "    sequence = \"\"\n",
    "    Sum = 0\n",
    "    CumSum = []\n",
    "    for n in range(0,len(First),2):\n",
    "        seq = First[n]\n",
    "        Sum = Sum + len(seq)\n",
    "        sequence = sequence + seq\n",
    "        CumSum.append(Sum)          \n",
    "            \n",
    "    # Prediction\n",
    "    x = one_hot_encode('N'*(context//2) + sequence + 'N'*(context//2))[None, :]\n",
    "    y = np.mean([models[m].predict(x) for m in range(5)], axis=0)\n",
    "    m6AAI_prob = y[0, :, 1]\n",
    "    m6AAI_prob = m6AAI_prob.tolist()        \n",
    "        \n",
    "    # Define probability in cDNA\n",
    "    First_prob = [m6AAI_prob[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        prob = m6AAI_prob[(CumSum[m-1]):(CumSum[m])]\n",
    "        First_prob.append(prob)\n",
    "    \n",
    "    \n",
    "    # Define intron length\n",
    "    IntronLength = []\n",
    "    for n in range(1,len(Length),2):\n",
    "        intron = Length[n]\n",
    "        IntronLength.append(intron)\n",
    "    IntronLength.append(0)   \n",
    "    \n",
    "    Probability = []\n",
    "    for o in range(0,len(First_prob),1):\n",
    "        List = First_prob[o]\n",
    "        Intron = [0]*IntronLength[o]\n",
    "        Probability.append(List+Intron)    \n",
    "    \n",
    "    iM6A_prob = []\n",
    "    for t in Probability:\n",
    "        iM6A_prob = iM6A_prob + t\n",
    "    Probability = iM6A_prob        \n",
    "    \n",
    "    Probability = pd.DataFrame({'Probability':Probability})\n",
    "    Probability.sort_index(inplace=True, ascending=False)\n",
    "    Probability = Probability.reset_index(drop = True)\n",
    "    df = pd.DataFrame(np.random.randn((Fasta_Neg.loc[i,\"Length\"]), 3))\n",
    "    df.columns = [\"name\", \"chrom\", \"strand\"]\n",
    "    df[\"name\"] = Fasta_Neg.loc[i,\"name\"]\n",
    "    df[\"chrom\"] = Fasta_Neg.loc[i,\"chrom\"]\n",
    "    df[\"strand\"] = Fasta_Neg.loc[i,\"strand\"]\n",
    "    \n",
    "    list = range(Fasta_Neg.loc[i,\"txStart\"], Fasta_Neg.loc[i,\"txEnd\"])\n",
    "    Start = pd.DataFrame(list, columns=[\"Start\"])\n",
    "    df = pd.concat([df, Start], axis=1)    \n",
    "    df[\"End\"] = df[\"Start\"]\n",
    "    df = pd.concat([df, Probability], axis=1)    \n",
    "    \n",
    "    df.columns = [\"name\", \"chrom\", \"strand\", \"Start\", \"End\", \"Probabilty\"]\n",
    "    df = df[df[\"Probabilty\"] >= 0.001]\n",
    "    df.to_csv(\"./OutputsIL/{}.bed\".format(Fasta_Neg.loc[i,\"name\"]), sep=\"\\t\", index=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
