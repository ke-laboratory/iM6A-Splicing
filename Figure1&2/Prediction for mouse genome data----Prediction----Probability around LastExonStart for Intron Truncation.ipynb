{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kelab/m6AAIpy2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from pkg_resources import resource_filename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import keras.backend as kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(seq):\n",
    "\n",
    "    map = np.asarray([[0, 0, 0, 0],\n",
    "                      [1, 0, 0, 0],\n",
    "                      [0, 1, 0, 0],\n",
    "                      [0, 0, 1, 0],\n",
    "                      [0, 0, 0, 1]])\n",
    "\n",
    "    seq = seq.upper().replace('A', '\\x01').replace('C', '\\x02')\n",
    "    seq = seq.replace('G', '\\x03').replace('T', '\\x04').replace('N', '\\x00')\n",
    "\n",
    "    return map[np.fromstring(seq, np.int8) % 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy_2d(y_true, y_pred):\n",
    "    # Standard categorical cross entropy for sequence outputs\n",
    "\n",
    "    return - kb.mean(y_true[:, :, 0]*kb.log(y_pred[:, :, 0]+1e-10)\n",
    "                   + y_true[:, :, 1]*kb.log(y_pred[:, :, 1]+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ('/home/kelab/Desktop/iM6A/mouseRAC10000_c{}.h5'.format(x) for x in range(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kelab/m6AAIpy2/keras/backend/tensorflow_backend.py:1154: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/kelab/m6AAIpy2/keras/backend/tensorflow_backend.py:1190: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/kelab/m6AAIpy2/keras/backend/tensorflow_backend.py:1297: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "models = [load_model(y, custom_objects={'categorical_crossentropy_2d': categorical_crossentropy_2d}) for y in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7f4d36fea650>,\n",
       " <keras.engine.training.Model at 0x7f4d31840810>,\n",
       " <keras.engine.training.Model at 0x7f4baa1d0d10>,\n",
       " <keras.engine.training.Model at 0x7f4a4d19ddd0>,\n",
       " <keras.engine.training.Model at 0x7f4a489c7e90>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta = pd.read_csv(\"Temp/mm10_LastIntron_Fasta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta = Fasta[Fasta[\"exonCount\"]>=3]\n",
    "Fasta = Fasta.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select positive strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Pos = Fasta[Fasta[\"strand\"]==\"+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Pos = Fasta_Pos.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequence = Fasta_Pos[\"Sequence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(range(-1000,1001),columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Fasta_Pos)):\n",
    "    \n",
    "    # Define exon location   \n",
    "    Exon = []\n",
    "    a = Fasta_Pos.loc[i, \"exonStarts\"].split(\",\")[0:-1]\n",
    "    b = Fasta_Pos.loc[i, \"exonEnds\"].split(\",\")[0:-1]\n",
    "    A = [int(u) for u in a]\n",
    "    B = [int(v) for v in b]\n",
    "    Exon = A + B\n",
    "    Exon = sorted(Exon)\n",
    "    \n",
    "    # Define length of exon and intron\n",
    "    Length = []\n",
    "    for j in range(1,len(Exon),1):\n",
    "        length = Exon[j] - Exon[-1 + j]\n",
    "        Length.append(length)\n",
    "    \n",
    "    CumSum = []\n",
    "    Sum = 0\n",
    "    for k in Length:\n",
    "        Sum = Sum + k\n",
    "        CumSum.append(Sum)    \n",
    "    \n",
    "    ## Define sequence of exon and intron\n",
    "    input_sequence = Sequence[i]\n",
    "    First = [input_sequence[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        seq = input_sequence[(CumSum[m-1]):(CumSum[m])]\n",
    "        First.append(seq)\n",
    "    \n",
    "    # Define sequence of exons\n",
    "    ExonSeq = []\n",
    "    for n in range(0,len(First),2):\n",
    "        seq = First[n]\n",
    "        ExonSeq.append(seq)\n",
    "   \n",
    "    # Define sequence of introns   \n",
    "    IntronSeq = []\n",
    "    for n in range(1,len(First),2):\n",
    "        seq = First[n]\n",
    "        if len(seq)>=400:\n",
    "            seq = seq[0:200] + seq[-200:]\n",
    "        if len(seq)<400:\n",
    "            seq = seq\n",
    "        IntronSeq.append(seq)\n",
    "    \n",
    "    # Define length of exons\n",
    "    ExonLength = []\n",
    "    for t in ExonSeq:\n",
    "        ExonLength.append(len(t))\n",
    "\n",
    "    # Define length of introns\n",
    "    IntronLength = []\n",
    "    for t in IntronSeq:\n",
    "        IntronLength.append(len(t))\n",
    "    IntronLength.append(0)\n",
    "    IntronSeq.append(\"\")\n",
    "    \n",
    "    # Define exon and intron length in transcript\n",
    "    Length = []\n",
    "    for t in range(0,len(ExonLength),1):\n",
    "        length1 = ExonLength[t]\n",
    "        length2 = IntronLength[t]\n",
    "        Length.append(length1)        \n",
    "        Length.append(length2)\n",
    "    Length.pop()\n",
    "    \n",
    "    # Define transcript\n",
    "    Transcript = \"\"\n",
    "    for t in range(0,len(ExonSeq),1):\n",
    "        seq1 = ExonSeq[t]\n",
    "        seq2 = IntronSeq[t]\n",
    "        Transcript = Transcript + seq1 + seq2\n",
    "\n",
    "    ## Predict truncated transcript\n",
    "    input_sequence = Transcript\n",
    "    x = one_hot_encode('N'*(context//2) + input_sequence + 'N'*(context//2))[None, :]\n",
    "    y = np.mean([models[m].predict(x) for m in range(5)], axis=0)\n",
    "    m6AAI_prob = y[0, :, 1]\n",
    "    m6AAI_prob = m6AAI_prob.tolist()\n",
    "    \n",
    "    # Define prob in exons\n",
    "    CumSum = []\n",
    "    Sum = 0\n",
    "    for k in Length:\n",
    "        Sum = Sum + k\n",
    "        CumSum.append(Sum)    \n",
    "    \n",
    "    First_prob = [m6AAI_prob[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        prob = m6AAI_prob[(CumSum[m-1]):(CumSum[m])]\n",
    "        First_prob.append(prob)    \n",
    " \n",
    "    Probability = []\n",
    "    for n in range(0,len(First_prob),2):\n",
    "        List = First_prob[n]\n",
    "        Probability.append(List)\n",
    "\n",
    "    iM6A_prob = []\n",
    "    for t in Probability:\n",
    "        iM6A_prob = iM6A_prob + t\n",
    "        \n",
    "    Start = 0\n",
    "    for t in range(len(Probability)-1):\n",
    "        Start = Start + len(Probability[t])        \n",
    "    \n",
    "    Pre = iM6A_prob[0:Start]\n",
    "    Last = iM6A_prob[Start:]\n",
    "    \n",
    "    if len(Pre) < 1000:\n",
    "        Pre = [0]*(1000-Start) + Pre\n",
    "    if len(Pre) >= 1000:\n",
    "        Pre = Pre[-1000:]\n",
    "    \n",
    "    if len(Last) < 1001:\n",
    "        Last = Last + [0]*(1001-len(Last))\n",
    "    if len(Last) >= 1001:\n",
    "        Last = Last[0:1001]\n",
    "    \n",
    "    New = np.array(Pre + Last)\n",
    "    New = pd.DataFrame({Fasta_Pos.loc[i,\"name\"]:New})\n",
    "    \n",
    "    df = pd.merge(df, New, left_index=True, right_index=True)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select negative strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Neg = Fasta[Fasta[\"strand\"]==\"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta_Neg = Fasta_Neg.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequence = Fasta_Neg[\"Sequence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Fasta_Neg)):\n",
    "    \n",
    "    # Define exon location\n",
    "    Exon = []\n",
    "    a = Fasta_Neg.loc[i, \"exonStarts\"].split(\",\")[0:-1]\n",
    "    b = Fasta_Neg.loc[i, \"exonEnds\"].split(\",\")[0:-1]\n",
    "    A = [int(u) for u in a]\n",
    "    B = [int(v) for v in b]\n",
    "    Exon = A + B\n",
    "    Exon = sorted(Exon)\n",
    "    \n",
    "    # Define length of exon and intron\n",
    "    Length = []\n",
    "    for j in range(1,len(Exon),1):\n",
    "        length = Exon[j] - Exon[-1 + j]\n",
    "        Length.append(length)\n",
    "    Length = Length[::-1]\n",
    "    \n",
    "    CumSum = []\n",
    "    Sum = 0\n",
    "    for k in Length:\n",
    "        Sum = Sum + k\n",
    "        CumSum.append(Sum)\n",
    "   \n",
    "    ## Define sequence of exon and intron\n",
    "    input_sequence = Sequence[i]\n",
    "    First = [input_sequence[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        seq = input_sequence[(CumSum[m-1]):(CumSum[m])]\n",
    "        First.append(seq)\n",
    "    \n",
    "    # Define sequence of exons\n",
    "    ExonSeq = []\n",
    "    for n in range(0,len(First),2):\n",
    "        seq = First[n]\n",
    "        ExonSeq.append(seq)\n",
    "   \n",
    "    # Define sequence of introns   \n",
    "    IntronSeq = []\n",
    "    for n in range(1,len(First),2):\n",
    "        seq = First[n]\n",
    "        if len(seq)>=400:\n",
    "            seq = seq[0:200] + seq[-200:]\n",
    "        if len(seq)<400:\n",
    "            seq = seq\n",
    "        IntronSeq.append(seq)\n",
    "    \n",
    "    # Define length of exons\n",
    "    ExonLength = []\n",
    "    for t in ExonSeq:\n",
    "        ExonLength.append(len(t))\n",
    "\n",
    "    # Define length of introns\n",
    "    IntronLength = []\n",
    "    for t in IntronSeq:\n",
    "        IntronLength.append(len(t))\n",
    "    IntronLength.append(0)\n",
    "    IntronSeq.append(\"\")\n",
    "    \n",
    "    # Define exon and intron length in transcript\n",
    "    Length = []\n",
    "    for t in range(0,len(ExonLength),1):\n",
    "        length1 = ExonLength[t]\n",
    "        length2 = IntronLength[t]\n",
    "        Length.append(length1)        \n",
    "        Length.append(length2)\n",
    "    Length.pop()\n",
    "    \n",
    "    # Define transcript\n",
    "    Transcript = \"\"\n",
    "    for t in range(0,len(ExonSeq),1):\n",
    "        seq1 = ExonSeq[t]\n",
    "        seq2 = IntronSeq[t]\n",
    "        Transcript = Transcript + seq1 + seq2\n",
    "    \n",
    "    ## Predict truncated transcript\n",
    "    input_sequence = Transcript\n",
    "    x = one_hot_encode('N'*(context//2) + input_sequence + 'N'*(context//2))[None, :]\n",
    "    y = np.mean([models[m].predict(x) for m in range(5)], axis=0)\n",
    "    m6AAI_prob = y[0, :, 1]\n",
    "    m6AAI_prob = m6AAI_prob.tolist()    \n",
    "    \n",
    "    CumSum = []\n",
    "    Sum = 0\n",
    "    for k in Length:\n",
    "        Sum = Sum + k\n",
    "        CumSum.append(Sum)\n",
    "\n",
    "    # Define prob in exons\n",
    "    First_prob = [m6AAI_prob[0:CumSum[0]]]\n",
    "    for m in range(1,len(CumSum),1):\n",
    "        prob = m6AAI_prob[(CumSum[m-1]):(CumSum[m])]\n",
    "        First_prob.append(prob)\n",
    "    \n",
    "    Probability = []\n",
    "    for n in range(0,len(First_prob),2):\n",
    "        List = First_prob[n]\n",
    "        Probability.append(List)\n",
    "\n",
    "    iM6A_prob = []\n",
    "    for t in Probability:\n",
    "        iM6A_prob = iM6A_prob + t\n",
    "        \n",
    "    Start = 0\n",
    "    for t in range(len(Probability)-1):\n",
    "        Start = Start + len(Probability[t])        \n",
    "    \n",
    "    Pre = iM6A_prob[0:Start]\n",
    "    Last = iM6A_prob[Start:]\n",
    "    \n",
    "    if len(Pre) < 1000:\n",
    "        Pre = [0]*(1000-Start) + Pre\n",
    "    if len(Pre) >= 1000:\n",
    "        Pre = Pre[-1000:]\n",
    "    \n",
    "    if len(Last) < 1001:\n",
    "        Last = Last + [0]*(1001-len(Last))\n",
    "    if len(Last) >= 1001:\n",
    "        Last = Last[0:1001]\n",
    "    \n",
    "    New = np.array(Pre + Last)\n",
    "    New = pd.DataFrame({Fasta_Neg.loc[i,\"name\"]:New})\n",
    "    \n",
    "    df = pd.merge(df, New, left_index=True, right_index=True)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"index\"], axis=1, inplace=True)\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"Sum\"] = df.sum()\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Value = df[[\"Sum\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Value.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Sum\"], axis=1, inplace=True)\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"Number\"] = (df > 0).sum()\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number = df[[\"Number\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.concat([Value, Number], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[\"Mean\"] = Data[\"Sum\"]/Data[\"Number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.head(2000)\n",
    "Sum = []\n",
    "Number = []\n",
    "\n",
    "for j in range(0,len(Data),10):\n",
    "\n",
    "    a = Data.loc[j:(j+9),\"Sum\"]\n",
    "    b = np.mean(a, axis=0)\n",
    "    Sum.append(b)\n",
    "    \n",
    "    a = Data.loc[j:(j+9),\"Number\"]\n",
    "    b = np.mean(a, axis=0)\n",
    "    Number.append(b)\n",
    "\n",
    "Result = pd.DataFrame({\"Index\":range(-1000,1000,10), \"Sum\":Sum, \"Number\":Number})\n",
    "Result[\"Mean\"] = Result[\"Sum\"]/Result[\"Number\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.to_csv(\"Mouse_iM6A_LastExonStart_10interval_IntronTruncation.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
